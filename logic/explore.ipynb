{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from sort import Sort\n",
    "\n",
    "model_config = 'src/yolov3.cfg'\n",
    "model_weights = 'src/yolov3.weights'\n",
    "\n",
    "class ObjectDetector():\n",
    "    def __init__(self):\n",
    "        net = cv2.dnn.readNet(model_config,model_weights)\n",
    "        self.model = cv2.dnn_DetectionModel(net)\n",
    "        self.model.setInputParams(size=(416,416),scale=1/255)\n",
    "        self.classes_allowed = [0]\n",
    "        \n",
    "    def detect(self,img):\n",
    "        bboxes = []\n",
    "        class_ids,scores,boxes = self.model.detect(img,nmsThreshold=0.4)\n",
    "        for class_id, score,box in zip(class_ids,scores,boxes):\n",
    "            if score < 0.3:\n",
    "                continue\n",
    "            \n",
    "            if class_id in self.classes_allowed:\n",
    "                x,y,w,h = [a for a in box]\n",
    "                box = [x,y,x+w,y+h,score]\n",
    "                bboxes.append(np.array(box).astype('int64'))\n",
    "        return np.array(bboxes)\n",
    "    \n",
    "def check(x1,y1,x2,y2,width,height):\n",
    "    if x1<=0 or y1<=0 or x2>=width or y2>=height:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = np.array([[[637,717],\n",
    "                [1055,573],\n",
    "                [1261,673],\n",
    "                [1192,709]]],np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roi(pts,color,frame):\n",
    "    alpha = 0.95\n",
    "    #create overlay\n",
    "    overlay = np.zeros_like(frame,np.uint8)\n",
    "    #draw\n",
    "    cv2.fillPoly(overlay,pts,color)\n",
    "    mask = overlay.copy().astype(bool)\n",
    "    frame[mask] = cv2.addWeighted(frame, alpha, overlay, 1 - alpha, 0)[mask]\n",
    "    cv2.polylines(frame,roi,True,(122,34,25),1)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ObjectDetector()\n",
    "mot = Sort()\n",
    "\n",
    "cap = cv2.VideoCapture('src/test.mp4')\n",
    "width  = int(cap.get(3)) # float `width`\n",
    "height = int(cap.get(4))\n",
    "tracked = []\n",
    "people_count= []\n",
    "if not cap.isOpened():\n",
    "    print('there is a error openning the video file')\n",
    "else:\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imwrite('file.jpg',frame)\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        if ret :\n",
    "            bboxes = detector.detect(frame)\n",
    "            tracked = mot.update(bboxes)\n",
    "            for person in tracked:\n",
    "                x1,y1,x2,y2,id = [int(a) for a in person]\n",
    "                #checking if person crossed roi\n",
    "                c = [(x1+x2)//2,(y1+y2)//2]\n",
    "                crossed = cv2.pointPolygonTest(roi,c,False)\n",
    "                if crossed==1 and id not in people_count and check(x1,y1,x2,y2,width,height):\n",
    "                    people_count.append(id)\n",
    "                print(people_count)\n",
    "                cv2.rectangle(frame,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "                cv2.putText(frame,str(id),(x1,y1),cv2.FONT_HERSHEY_SIMPLEX,1,(0,124,255),2)\n",
    "                cv2.putText(frame,f'people count:{len(people_count)}',(30,45),cv2.FONT_HERSHEY_COMPLEX,2,(0,0,255),3)\n",
    "                frame = draw_roi(roi,(135,0,255),frame)\n",
    "            cv2.imshow('video',frame)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else :\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "        \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = ObjectDetector()\n",
    "trackers = cv2.legacy.MultiTracker_create()\n",
    "cap = cv2.VideoCapture('src/test.mp4')\n",
    "ret,frame = cap.read()\n",
    "width  = cap.get(3)  # float `width`\n",
    "height = cap.get(4)\n",
    "boxes = detector.detect(frame)\n",
    "for box in boxes:\n",
    "    tracker_j = cv2.legacy.TrackerCSRT_create()\n",
    "    trackers.add(tracker_j,frame,box)\n",
    "\n",
    "persons = {}\n",
    "id = 0\n",
    "initial = True\n",
    "if not cap.isOpened():\n",
    "    print('there is a error openning the video file')\n",
    "else:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        if ret :\n",
    "            (success,boxes) = trackers.update(frame)\n",
    "            # intializing persons\n",
    "            if initial:\n",
    "                for box in boxes:\n",
    "                    persons[id] = box\n",
    "                    id+=1\n",
    "                initial =False\n",
    "            \n",
    "            for (box,(id,person)) in zip(boxes,persons.copy().items()):\n",
    "                (x,y,w,h) = person\n",
    "                if not initial:\n",
    "                    persons[id] = box\n",
    "                # if some object goes beyond limits of frame\n",
    "                if not check(x,y,w,h,height,width):\n",
    "                    persons.pop(id)\n",
    "                    del trackers\n",
    "                    trackers = cv2.legacy.MultiTracker_create()\n",
    "                    new_bbs = detector.detect(frame)\n",
    "                    for box in new_bbs:\n",
    "                        same = False\n",
    "                        #checks if bbox is the same \n",
    "                        for key,value in persons.copy().items():\n",
    "                            x1,y1,w1,h1 = box\n",
    "                            x2,y2,w2,h2 = value\n",
    "                            c1 = [x1+w1//2,y1+h1//2]\n",
    "                            c2 = [x2+w2//2,y2+h2//2]\n",
    "                            if math.dist(c1,c2)<5:\n",
    "                                same = True\n",
    "                                persons[key] = box\n",
    "                        if same:\n",
    "                            tracker = cv2.legacy.TrackerCSRT_create()\n",
    "                            trackers.add(tracker,frame,box)\n",
    "                        # if new object, track it\n",
    "                        else:\n",
    "                            x,y,w,h = box\n",
    "                            if check(x,y,w,h,height,width):\n",
    "                                id+=1\n",
    "                                persons[id] = box\n",
    "                                tracker = cv2.legacy.TrackerCSRT_create()\n",
    "                                trackers.add(tracker,frame,box)\n",
    "            print(persons)\n",
    "            for id,person in persons.items():\n",
    "                (x,y,w,h) = [int(a) for a in person]\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,12,255),2)\n",
    "                cv2.putText(frame,str(id),(x,y),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)\n",
    "            cv2.imshow('video',frame)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else :\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import cv2\n",
    "import numpy as np\n",
    "capture = cv2.VideoCapture('src/test.mp4')\n",
    "background_subtractor = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "length = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "\n",
    "\n",
    "first_iteration_indicator = 1\n",
    "for i in range(0, length):\n",
    "\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # If first frame\n",
    "    if first_iteration_indicator == 1:\n",
    "\n",
    "        first_frame = copy.deepcopy(frame)\n",
    "        height, width = frame.shape[:2]\n",
    "        accum_image = np.zeros((height, width), np.uint8)\n",
    "        \n",
    "        first_iteration_indicator = 0\n",
    "    else:\n",
    "        filter = background_subtractor.apply(frame)  # remove the background\n",
    "\n",
    "        threshold = 2\n",
    "        maxValue = 2\n",
    "        ret, th1 = cv2.threshold(filter, threshold, maxValue, cv2.THRESH_BINARY)\n",
    "\n",
    "        # add to the accumulated image\n",
    "        accum_image = cv2.add(accum_image, th1)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        color_image = cv2.applyColorMap(accum_image, cv2.COLORMAP_JET)\n",
    "        result_overlay = cv2.addWeighted(frame, 0.7, color_image, 0.7, 0)\n",
    "        cv2.imshow('video',result_overlay)\n",
    "cv2.imwrite('result.jpg',result_overlay)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c552931fb620b60b927d393c6464ee521e771bb8b6920714febc020bd5f2901f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('deep_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
